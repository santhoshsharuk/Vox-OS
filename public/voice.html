<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Vox OS Voice Recognition</title>
  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
      background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
      display: flex;
      align-items: center;
      justify-content: center;
      min-height: 100vh;
      color: white;
    }

    .voice-container {
      text-align: center;
      padding: 40px;
      background: rgba(255, 255, 255, 0.1);
      backdrop-filter: blur(10px);
      border-radius: 20px;
      box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
      max-width: 400px;
      width: 90%;
    }

    h1 {
      font-size: 24px;
      margin-bottom: 10px;
    }

    .status {
      font-size: 14px;
      opacity: 0.9;
      margin-bottom: 30px;
    }

    .mic-icon {
      font-size: 80px;
      margin: 20px 0;
      animation: pulse 2s infinite;
    }

    @keyframes pulse {
      0%, 100% { transform: scale(1); opacity: 1; }
      50% { transform: scale(1.1); opacity: 0.8; }
    }

    .listening {
      animation: listening 1s infinite;
    }

    @keyframes listening {
      0%, 100% { transform: scale(1); }
      50% { transform: scale(1.2); }
    }

    .transcript {
      background: rgba(0, 0, 0, 0.2);
      padding: 15px;
      border-radius: 10px;
      min-height: 60px;
      margin-top: 20px;
      font-size: 16px;
      line-height: 1.5;
    }

    .connection-status {
      margin-top: 20px;
      padding: 10px;
      border-radius: 8px;
      font-size: 12px;
    }

    .connected {
      background: rgba(16, 185, 129, 0.3);
      border: 1px solid rgba(16, 185, 129, 0.5);
    }

    .disconnected {
      background: rgba(239, 68, 68, 0.3);
      border: 1px solid rgba(239, 68, 68, 0.5);
    }

    .error {
      background: rgba(239, 68, 68, 0.2);
      padding: 10px;
      border-radius: 8px;
      margin-top: 15px;
      font-size: 13px;
    }

    .close-btn {
      position: absolute;
      top: 15px;
      right: 15px;
      background: rgba(255, 255, 255, 0.2);
      border: none;
      color: white;
      width: 30px;
      height: 30px;
      border-radius: 50%;
      cursor: pointer;
      font-size: 18px;
      transition: background 0.3s;
    }

    .close-btn:hover {
      background: rgba(255, 255, 255, 0.3);
    }
  </style>
</head>
<body>
  <button class="close-btn" onclick="window.close()" title="Close">√ó</button>
  
  <div class="voice-container">
    <h1>üé§ Vox OS Voice (Background)</h1>
    <p class="status" id="status">Running in background...</p>
    
    <div class="mic-icon" id="micIcon">üéôÔ∏è</div>
    
    <div class="transcript" id="transcript">
      Listening in background... This window can be minimized!
    </div>
    
    <div class="connection-status disconnected" id="connectionStatus">
      ‚ö†Ô∏è Connecting to Vox OS...
    </div>
    
    <div class="error" id="error" style="display: none;"></div>
    
    <p style="font-size: 11px; opacity: 0.7; margin-top: 15px;">
      üí° Minimize this window - voice recognition keeps working!
    </p>
  </div>

  <script>
    let ws = null;
    let recognition = null;
    let reconnectTimer = null;

    const statusEl = document.getElementById('status');
    const micIcon = document.getElementById('micIcon');
    const transcriptEl = document.getElementById('transcript');
    const connectionStatus = document.getElementById('connectionStatus');
    const errorEl = document.getElementById('error');

    function showError(message) {
      errorEl.textContent = '‚ùå ' + message;
      errorEl.style.display = 'block';
    }

    function hideError() {
      errorEl.style.display = 'none';
    }

    function connectWebSocket() {
      try {
        ws = new WebSocket('ws://localhost:9001');

        ws.onopen = () => {
          console.log('‚úÖ Connected to Vox OS');
          connectionStatus.textContent = '‚úÖ Connected to Vox OS';
          connectionStatus.className = 'connection-status connected';
          hideError();
          startVoiceRecognition();
        };

        ws.onclose = () => {
          console.log('‚ùå Disconnected from Vox OS');
          connectionStatus.textContent = '‚ö†Ô∏è Disconnected - Retrying...';
          connectionStatus.className = 'connection-status disconnected';
          
          // Try to reconnect after 2 seconds
          if (reconnectTimer) clearTimeout(reconnectTimer);
          reconnectTimer = setTimeout(connectWebSocket, 2000);
        };

        ws.onerror = (error) => {
          console.error('WebSocket error:', error);
          showError('Connection failed. Make sure Vox OS is running.');
        };

      } catch (error) {
        console.error('Failed to create WebSocket:', error);
        showError('Failed to connect to Vox OS');
      }
    }

    function startVoiceRecognition() {
      // Check for Web Speech API support
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      
      if (!SpeechRecognition) {
        showError('Speech recognition not supported. Please use Google Chrome.');
        return;
      }

      recognition = new SpeechRecognition();
      recognition.continuous = true;
      recognition.interimResults = true;
      recognition.lang = 'en-US'; // Change to 'ta-IN' for Tamil, 'hi-IN' for Hindi

      recognition.onstart = () => {
        console.log('üé§ Voice recognition started');
        statusEl.textContent = 'Listening... Speak now!';
        micIcon.classList.add('listening');
      };

      recognition.onresult = (event) => {
        const result = event.results[event.results.length - 1];
        const transcript = result[0].transcript;
        
        if (result.isFinal) {
          console.log('Final:', transcript);
          transcriptEl.textContent = transcript;
          
          // Send to Vox OS via WebSocket
          if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send(transcript);
          }
        } else {
          // Show interim results
          transcriptEl.textContent = transcript + '...';
        }
      };

      recognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        
        if (event.error === 'no-speech') {
          // Ignore no-speech errors, just keep listening
          return;
        }
        
        if (event.error === 'network') {
          showError('Network error. Check your internet connection.');
        } else if (event.error === 'not-allowed') {
          showError('Microphone permission denied. Please allow microphone access.');
        } else {
          showError('Recognition error: ' + event.error);
        }
      };

      recognition.onend = () => {
        console.log('Recognition ended, restarting...');
        micIcon.classList.remove('listening');
        
        // Auto-restart after a short delay
        setTimeout(() => {
          if (ws && ws.readyState === WebSocket.OPEN) {
            recognition.start();
          }
        }, 500);
      };

      // Start recognition
      try {
        recognition.start();
      } catch (error) {
        console.error('Failed to start recognition:', error);
        showError('Failed to start voice recognition');
      }
    }

    // Start connection when page loads
    connectWebSocket();

    // Cleanup on page unload
    window.addEventListener('beforeunload', () => {
      if (recognition) {
        recognition.stop();
      }
      if (ws) {
        ws.close();
      }
      if (reconnectTimer) {
        clearTimeout(reconnectTimer);
      }
    });
  </script>
</body>
</html>
